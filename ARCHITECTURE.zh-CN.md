# 架构设计

## 概述

```
┌─────────────────────────────────────────────────────────────────┐
│                        训练流程                                   │
├─────────────────────────────────────────────────────────────────┤
│  ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐  │
│  │  数据    │───▶│ 采样器   │───▶│  模型    │───▶│  损失    │  │
│  │  加载器  │    │ (Warp)   │    │ (前向)   │    │  计算    │  │
│  └──────────┘    └──────────┘    └──────────┘    └──────────┘  │
│       │                               │                │        │
│       ▼                               ▼                ▼        │
│  ┌──────────┐                 ┌──────────┐    ┌──────────┐      │
│  │  数据集  │                 │ 反向传播 │    │ 优化器   │      │
│  │  (Utils) │                 │ (Autograd)│   │ (Adam)   │      │
│  └──────────┘                 └──────────┘    └──────────┘      │
└─────────────────────────────────────────────────────────────────┘
```

## 目录结构

```
python/
├── main.py              # 统一训练入口
│
├── model.py             # 基础模型
│   ├── SASRec           # 标准自注意力序列推荐
│   └── TiSASRec         # 时序感知自注意力
│
├── model_mhc.py         # 带mHC的模型变体
│   ├── SASRec_mHC       # SASRec + 流形约束超连接
│   └── TiSASRec_mHC     # TiSASRec + 流形约束超连接
│
├── utils.py             # 核心工具
│   ├── DataPartition    # 训练/验证/测试集划分
│   ├── WarpSampler      # 负采样
│   ├── WarpSamplerWithTime  # 时序感知采样
│   ├── evaluate()       # SASRec评估
│   └── evaluate_tisasrec()  # TiSASRec评估
│
└── convert_ml1m.py      # MovieLens 1M数据转换
```

## 模型架构

### SASRec

```
输入: (batch, seq_len) 商品索引
    │
    ▼
┌───────────────────┐
│   商品嵌入层      │──▶ (batch, seq_len, hidden_units)
│   (n_items, C)    │
└───────────────────┘
    │
    ▼
┌───────────────────┐
│  位置嵌入层       │──▶ (1, max_len, C)
│   (可学习)        │
└───────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────────┐
│                   Transformer 块                         │
│  ┌─────────────────────────────────────────────────┐   │
│  │ 块 i:                                          │   │
│  │  1. 多头自注意力                               │   │
│  │     Q, K, V = Linear(C→C) × 3                  │   │
│  │     Attention = softmax(QK^T / √d) V           │   │
│  │                                               │   │
│  │  2. 残差连接 & 层归一化                        │   │
│  │                                               │   │
│  │  3. 前馈神经网络                               │   │
│  │     FFN(x) = W2(ReLU(W1 x + b1)) + b2         │   │
│  │                                               │   │
│  │  4. 残差连接 & 层归一化                        │   │
│  └─────────────────────────────────────────────────┘   │
│                          :                              │
│                    (num_blocks)                          │
└─────────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────┐
│  最终层归一化                            │
│         +                                │
│  Linear(C → n_items) → logits           │
└─────────────────────────────────────────┘
```

### TiSASRec (时序感知)

```
SASRec + 时间矩阵注入注意力:

标准注意力:
    A_ij = softmax(Q_i · K_j^T)

TiSASRec 注意力:
    A_ij = softmax(Q_i · K_j^T 
                   + Q_i · abs_pos_K_i^T 
                   + time_matrix_K_j · Q_i)

额外组件:
┌─────────────────────────────────────────┐
│  时间矩阵嵌入                           │
│  (time_span, hidden_units)              │
│  - 编码相对时间间隔                     │
│  - 在注意力头间共享                     │
└─────────────────────────────────────────┘
```

### mHC (流形约束超连接)

替换标准残差连接:

```
标准残差:
    x_{l+1} = x_l + F(x_l)

mHC 残差:
    x_{l+1} = H_res × x_l + H_post^T × F(H_pre × x_l)

其中:
    - H_pre: 输入投影 (nC → n), sigmoid激活
    - H_post: 输出投影 (nC → n), sigmoid激活  
    - H_res: 残差混合 (nC → n²), Sinkhorn-Knopp约束

mHC 模块结构:
┌──────────────────────────────────────────────────────────────┐
│ 输入: x ∈ (batch, seq, C)                                   │
│                                                              │
│  1. 扩展: repeat x → x_exp ∈ (batch, seq, n, C)            │
│                                                              │
│  2. H_pre: (batch, seq, n) ← sigmoid(Linear(x, n))         │
│                                                              │
│  3. H_post: (batch, seq, n) ← sigmoid(Linear(x, n))        │
│                                                              │
│  4. H_res: (batch, seq, n, n)                              │
│     - 初始化为双随机矩阵                                    │
│     - Sinkhorn-Knopp 迭代 (默认: 20)                        │
│                                                              │
│  5. 残差: x_res = H_res × x_exp → (batch, seq, n, C)       │
│                                                              │
│  6. 输出路径: f_out = H_post × F(H_pre × x) → (batch, seq, C)
│                                                              │
│  7. 合并: sum_n(x_res) + f_out                             │
└──────────────────────────────────────────────────────────────┘
```

## 数据流

```
训练流程:
┌─────────────────────────────────────────────────────────────┐
│  raw_data.txt (UserID, MovieID, Timestamp)                  │
│                      ↓                                      │
│  data_partition() → user_train, user_valid, user_test       │
│                      ↓                                      │
│  WarpSampler → (u, seq, pos, neg, [time_mat]) batches      │
│                      ↓                                      │
│  model.forward() → (pos_logits, neg_logits)                 │
│                      ↓                                      │
│  BCEWithLogitsLoss + L2正则化                               │
│                      ↓                                      │
│  Adam 优化器更新                                            │
└─────────────────────────────────────────────────────────────┘

推理流程:
┌─────────────────────────────────────────────────────────────┐
│  用户历史 (序列)                                             │
│                      ↓                                      │
│  model.predict() → 所有商品的得分                           │
│                      ↓                                      │
│  Top-K 评估 (NDCG@10, HR@10)                                │
└─────────────────────────────────────────────────────────────┘
```

## 关键设计决策

1. **统一训练脚本**: 单个 `main.py` 通过参数标志支持所有模型组合

2. **负采样**: 批次内负采样，商品分布均匀

3. **时间编码**: 相对时间间隔离散化到 `[1, time_span]`

4. **mHC集成**: 标准残差连接的即插即用替代

5. **评估方式**: 对所有商品完整排序（非采样），报告 NDCG@10 和 HR@10

## 依赖

```
torch >= 1.9.0
numpy
tqdm (可选，用于进度条)
```
